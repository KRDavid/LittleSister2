{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro / preparing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different datasets based on CIFAR 10 will be tested on a basic model using data augmentation. \n",
    "We will add layers of data augmentation one by one and see the evolution.\n",
    "\n",
    "Visualization of metrics is possible at the end of this notebook using TensorBoard\n",
    "\n",
    "If needed, you can find CIFAR 10 images at :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###### Local imports\n",
    "from src.model_utilities import train_model, create_model, retrieve_data\n",
    "\n",
    "###### Random imports\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "###### Tensorflow imports\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, Activation, Dropout, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "###### Sklearn imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "###### Setting global variables\n",
    "TRAIN_BASE_DIRECTORY = \"./data/train\"\n",
    "VAL_BASE_DIRECTORY = \"./data/test\"\n",
    "IMAGE_SIZE = 32\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initializing model\n",
    "\n",
    "We set up a basic model architecture which will be used for all trainings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16, 16, 64)        2112      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                40970     \n",
      "=================================================================\n",
      "Total params: 80,906\n",
      "Trainable params: 80,906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=3, activation='relu', padding='same', input_shape=(32,32,3))) \n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "#Fin obligatoire\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First dataset : vanilla\n",
    "\n",
    "We read the CIFAR 10 dataset and train the model as is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Setting the data generator\n",
    "datagen = ImageDataGenerator(validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40000 images belonging to 10 classes.\n",
      "Found 8000 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "####### Retrieving data using the ImageDataGenerator\n",
    "train_generator ,val_generator = retrieve_data(datagen,\n",
    "                                               TRAIN_BASE_DIRECTORY,\n",
    "                                               VAL_BASE_DIRECTORY,\n",
    "                                               BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\Python\\LittleSister2\\src\\model_utilities.py:15: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/20\n",
      "  1/625 [..............................] - ETA: 0s - loss: 31.2706 - accuracy: 0.0312WARNING:tensorflow:From C:\\Users\\drakk\\Anaconda3\\envs\\tensor\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "  2/625 [..............................] - ETA: 2:05 - loss: 30.7094 - accuracy: 0.0625WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0509s vs `on_train_batch_end` time: 0.3531s). Check your callbacks.\n",
      "625/625 [==============================] - 39s 62ms/step - loss: 2.1997 - accuracy: 0.3711 - val_loss: 1.5011 - val_accuracy: 0.4672\n",
      "Epoch 2/20\n",
      "625/625 [==============================] - 39s 62ms/step - loss: 1.3989 - accuracy: 0.5012 - val_loss: 1.3284 - val_accuracy: 0.5245\n",
      "Epoch 3/20\n",
      "625/625 [==============================] - 37s 59ms/step - loss: 1.2621 - accuracy: 0.5504 - val_loss: 1.2278 - val_accuracy: 0.5684\n",
      "Epoch 4/20\n",
      "625/625 [==============================] - 38s 60ms/step - loss: 1.1586 - accuracy: 0.5949 - val_loss: 1.2320 - val_accuracy: 0.5676\n",
      "Epoch 5/20\n",
      "625/625 [==============================] - 36s 58ms/step - loss: 1.0670 - accuracy: 0.6258 - val_loss: 1.2322 - val_accuracy: 0.5740\n",
      "Epoch 6/20\n",
      "625/625 [==============================] - 37s 59ms/step - loss: 1.0140 - accuracy: 0.6457 - val_loss: 1.1894 - val_accuracy: 0.5995\n",
      "Epoch 7/20\n",
      "625/625 [==============================] - 36s 58ms/step - loss: 0.9513 - accuracy: 0.6672 - val_loss: 1.1983 - val_accuracy: 0.5971\n",
      "Epoch 8/20\n",
      "625/625 [==============================] - 37s 59ms/step - loss: 0.8915 - accuracy: 0.6849 - val_loss: 1.1874 - val_accuracy: 0.6030\n",
      "Epoch 9/20\n",
      "625/625 [==============================] - 36s 58ms/step - loss: 0.8429 - accuracy: 0.7070 - val_loss: 1.2064 - val_accuracy: 0.6118\n",
      "Epoch 10/20\n",
      "625/625 [==============================] - 37s 59ms/step - loss: 0.7996 - accuracy: 0.7211 - val_loss: 1.2580 - val_accuracy: 0.6009\n",
      "Epoch 11/20\n",
      "625/625 [==============================] - 38s 60ms/step - loss: 0.7548 - accuracy: 0.7340 - val_loss: 1.2593 - val_accuracy: 0.6145\n",
      "Epoch 12/20\n",
      "625/625 [==============================] - 36s 57ms/step - loss: 0.7102 - accuracy: 0.7496 - val_loss: 1.3551 - val_accuracy: 0.6029\n",
      "Epoch 13/20\n",
      "625/625 [==============================] - 38s 61ms/step - loss: 0.6547 - accuracy: 0.7706 - val_loss: 1.3977 - val_accuracy: 0.5990\n",
      "Epoch 14/20\n",
      "625/625 [==============================] - 38s 61ms/step - loss: 0.6255 - accuracy: 0.7799 - val_loss: 1.4044 - val_accuracy: 0.6091\n",
      "Epoch 15/20\n",
      "625/625 [==============================] - 37s 59ms/step - loss: 0.5906 - accuracy: 0.7919 - val_loss: 1.4776 - val_accuracy: 0.5978\n",
      "Epoch 16/20\n",
      "625/625 [==============================] - 41s 65ms/step - loss: 0.5560 - accuracy: 0.8034 - val_loss: 1.5707 - val_accuracy: 0.5936\n",
      "Epoch 17/20\n",
      "625/625 [==============================] - 37s 60ms/step - loss: 0.5296 - accuracy: 0.8139 - val_loss: 1.7229 - val_accuracy: 0.5909\n",
      "Epoch 18/20\n",
      "625/625 [==============================] - 41s 65ms/step - loss: 0.5020 - accuracy: 0.8223 - val_loss: 1.6945 - val_accuracy: 0.6008\n",
      "Epoch 19/20\n",
      "625/625 [==============================] - 37s 59ms/step - loss: 0.4808 - accuracy: 0.8311 - val_loss: 1.7707 - val_accuracy: 0.6008\n",
      "Epoch 20/20\n",
      "625/625 [==============================] - 39s 62ms/step - loss: 0.4425 - accuracy: 0.8429 - val_loss: 1.8254 - val_accuracy: 0.6009\n"
     ]
    }
   ],
   "source": [
    "train_model(model, train_generator, val_generator, name=\"Base_Model\", n_epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding random rotation on image\n",
    "\n",
    "We add a random tilt between 0 and 20 degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Setting the data generator\n",
    "datagen20 = ImageDataGenerator(validation_split=0.2,\n",
    "                               rotation_range=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40000 images belonging to 10 classes.\n",
      "Found 8000 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "####### Retrieving data using the ImageDataGenerator\n",
    "train_generator20 ,val_generator20 = retrieve_data(datagen20,\n",
    "                                               TRAIN_BASE_DIRECTORY,\n",
    "                                               VAL_BASE_DIRECTORY,\n",
    "                                               BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16, 16, 64)        2112      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                40970     \n",
      "=================================================================\n",
      "Total params: 80,906\n",
      "Trainable params: 80,906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "  2/625 [..............................] - ETA: 4:34 - loss: 32.4368 - accuracy: 0.0703WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0718s vs `on_train_batch_end` time: 0.8102s). Check your callbacks.\n",
      "625/625 [==============================] - 58s 93ms/step - loss: 2.1921 - accuracy: 0.3376 - val_loss: 1.5709 - val_accuracy: 0.4396\n",
      "Epoch 2/20\n",
      "625/625 [==============================] - 53s 84ms/step - loss: 1.4884 - accuracy: 0.4704 - val_loss: 1.3816 - val_accuracy: 0.5098\n",
      "Epoch 3/20\n",
      "625/625 [==============================] - 54s 86ms/step - loss: 1.3777 - accuracy: 0.5143 - val_loss: 1.3561 - val_accuracy: 0.5156\n",
      "Epoch 4/20\n",
      "625/625 [==============================] - 54s 86ms/step - loss: 1.2834 - accuracy: 0.5466 - val_loss: 1.2589 - val_accuracy: 0.5558\n",
      "Epoch 5/20\n",
      "625/625 [==============================] - 53s 85ms/step - loss: 1.2229 - accuracy: 0.5706 - val_loss: 1.2424 - val_accuracy: 0.5625\n",
      "Epoch 6/20\n",
      "625/625 [==============================] - 53s 85ms/step - loss: 1.1718 - accuracy: 0.5867 - val_loss: 1.2144 - val_accuracy: 0.5769\n",
      "Epoch 7/20\n",
      "625/625 [==============================] - 54s 86ms/step - loss: 1.1389 - accuracy: 0.6011 - val_loss: 1.1564 - val_accuracy: 0.5943\n",
      "Epoch 8/20\n",
      "625/625 [==============================] - 54s 86ms/step - loss: 1.1073 - accuracy: 0.6111 - val_loss: 1.1592 - val_accuracy: 0.5940\n",
      "Epoch 9/20\n",
      "625/625 [==============================] - 52s 83ms/step - loss: 1.0774 - accuracy: 0.6225 - val_loss: 1.1356 - val_accuracy: 0.6009\n",
      "Epoch 10/20\n",
      "625/625 [==============================] - 52s 83ms/step - loss: 1.0541 - accuracy: 0.6318 - val_loss: 1.0954 - val_accuracy: 0.6176\n",
      "Epoch 11/20\n",
      "625/625 [==============================] - 60s 96ms/step - loss: 1.0319 - accuracy: 0.6420 - val_loss: 1.1331 - val_accuracy: 0.5994\n",
      "Epoch 12/20\n",
      "625/625 [==============================] - 59s 95ms/step - loss: 1.0096 - accuracy: 0.6468 - val_loss: 1.1022 - val_accuracy: 0.6146\n",
      "Epoch 13/20\n",
      "625/625 [==============================] - 60s 96ms/step - loss: 0.9960 - accuracy: 0.6506 - val_loss: 1.1189 - val_accuracy: 0.6140\n",
      "Epoch 14/20\n",
      "625/625 [==============================] - 61s 98ms/step - loss: 0.9716 - accuracy: 0.6628 - val_loss: 1.0672 - val_accuracy: 0.6309\n",
      "Epoch 15/20\n",
      "625/625 [==============================] - 58s 92ms/step - loss: 0.9623 - accuracy: 0.6661 - val_loss: 1.0844 - val_accuracy: 0.6246\n",
      "Epoch 16/20\n",
      "625/625 [==============================] - 53s 85ms/step - loss: 0.9399 - accuracy: 0.6730 - val_loss: 1.0558 - val_accuracy: 0.6359\n",
      "Epoch 17/20\n",
      "625/625 [==============================] - 52s 83ms/step - loss: 0.9239 - accuracy: 0.6761 - val_loss: 1.0645 - val_accuracy: 0.6396\n",
      "Epoch 18/20\n",
      "625/625 [==============================] - 53s 86ms/step - loss: 0.9161 - accuracy: 0.6796 - val_loss: 1.0478 - val_accuracy: 0.6375\n",
      "Epoch 19/20\n",
      "625/625 [==============================] - 58s 93ms/step - loss: 0.8971 - accuracy: 0.6894 - val_loss: 1.1098 - val_accuracy: 0.6161\n",
      "Epoch 20/20\n",
      "625/625 [==============================] - 55s 88ms/step - loss: 0.8856 - accuracy: 0.6911 - val_loss: 1.0707 - val_accuracy: 0.6386\n"
     ]
    }
   ],
   "source": [
    "model20 = create_model()\n",
    "\n",
    "train_model(model20, train_generator20, val_generator20, name=\"20percent_Rotation_Model\", n_epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding random horizontal flip\n",
    "\n",
    "Keeping the 20 degrees tilt we add a random horizontal flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Setting the data generator\n",
    "datagen20hflip = ImageDataGenerator(validation_split=0.2,\n",
    "                                    rotation_range=20,\n",
    "                                    horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40000 images belonging to 10 classes.\n",
      "Found 8000 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "####### Retrieving data using the ImageDataGenerator\n",
    "train_generator20hflip ,val_generator20hflip = retrieve_data(datagen20hflip,\n",
    "                                               TRAIN_BASE_DIRECTORY,\n",
    "                                               VAL_BASE_DIRECTORY,\n",
    "                                               BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16, 16, 64)        2112      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                40970     \n",
      "=================================================================\n",
      "Total params: 80,906\n",
      "Trainable params: 80,906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From d:\\Python\\LittleSister2\\src\\model_utilities.py:15: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/20\n",
      "  1/625 [..............................] - ETA: 0s - loss: 22.5547 - accuracy: 0.1406WARNING:tensorflow:From C:\\Users\\drakk\\Anaconda3\\envs\\tensor\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "  2/625 [..............................] - ETA: 2:19 - loss: 30.6049 - accuracy: 0.1250WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0529s vs `on_train_batch_end` time: 0.3929s). Check your callbacks.\n",
      "625/625 [==============================] - 56s 90ms/step - loss: 2.0224 - accuracy: 0.3872 - val_loss: 1.4677 - val_accuracy: 0.4720\n",
      "Epoch 2/20\n",
      "625/625 [==============================] - 57s 92ms/step - loss: 1.4276 - accuracy: 0.4907 - val_loss: 1.3285 - val_accuracy: 0.5247\n",
      "Epoch 3/20\n",
      "625/625 [==============================] - 55s 88ms/step - loss: 1.3485 - accuracy: 0.5217 - val_loss: 1.3084 - val_accuracy: 0.5385\n",
      "Epoch 4/20\n",
      "625/625 [==============================] - 55s 88ms/step - loss: 1.2744 - accuracy: 0.5523 - val_loss: 1.2458 - val_accuracy: 0.5571\n",
      "Epoch 5/20\n",
      "625/625 [==============================] - 53s 85ms/step - loss: 1.2305 - accuracy: 0.5672 - val_loss: 1.2338 - val_accuracy: 0.5573\n",
      "Epoch 6/20\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 1.1928 - accuracy: 0.5830 - val_loss: 1.1655 - val_accuracy: 0.5891\n",
      "Epoch 7/20\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 1.1684 - accuracy: 0.5901 - val_loss: 1.1585 - val_accuracy: 0.5956\n",
      "Epoch 8/20\n",
      "625/625 [==============================] - 61s 97ms/step - loss: 1.1324 - accuracy: 0.6066 - val_loss: 1.1615 - val_accuracy: 0.5962\n",
      "Epoch 9/20\n",
      "625/625 [==============================] - 63s 101ms/step - loss: 1.0945 - accuracy: 0.6183 - val_loss: 1.1029 - val_accuracy: 0.6150\n",
      "Epoch 10/20\n",
      "625/625 [==============================] - 61s 98ms/step - loss: 1.0758 - accuracy: 0.6290 - val_loss: 1.1278 - val_accuracy: 0.6109\n",
      "Epoch 11/20\n",
      "625/625 [==============================] - 62s 99ms/step - loss: 1.0541 - accuracy: 0.6331 - val_loss: 1.1111 - val_accuracy: 0.6120\n",
      "Epoch 12/20\n",
      "625/625 [==============================] - 57s 92ms/step - loss: 1.0327 - accuracy: 0.6428 - val_loss: 1.0769 - val_accuracy: 0.6258\n",
      "Epoch 13/20\n",
      "625/625 [==============================] - 57s 92ms/step - loss: 1.0128 - accuracy: 0.6482 - val_loss: 1.0415 - val_accuracy: 0.6384\n",
      "Epoch 14/20\n",
      "625/625 [==============================] - 64s 102ms/step - loss: 1.0041 - accuracy: 0.6515 - val_loss: 1.0439 - val_accuracy: 0.6428\n",
      "Epoch 15/20\n",
      "625/625 [==============================] - 63s 101ms/step - loss: 0.9921 - accuracy: 0.6548 - val_loss: 1.0581 - val_accuracy: 0.6385\n",
      "Epoch 16/20\n",
      "625/625 [==============================] - 61s 98ms/step - loss: 0.9661 - accuracy: 0.6641 - val_loss: 1.0560 - val_accuracy: 0.6363\n",
      "Epoch 17/20\n",
      "625/625 [==============================] - 62s 100ms/step - loss: 0.9587 - accuracy: 0.6656 - val_loss: 1.0442 - val_accuracy: 0.6411\n",
      "Epoch 18/20\n",
      "625/625 [==============================] - 61s 97ms/step - loss: 0.9469 - accuracy: 0.6730 - val_loss: 1.0092 - val_accuracy: 0.6540\n",
      "Epoch 19/20\n",
      "625/625 [==============================] - 65s 104ms/step - loss: 0.9392 - accuracy: 0.6735 - val_loss: 1.0109 - val_accuracy: 0.6518\n",
      "Epoch 20/20\n",
      "625/625 [==============================] - 60s 97ms/step - loss: 0.9308 - accuracy: 0.6773 - val_loss: 1.0263 - val_accuracy: 0.6492\n"
     ]
    }
   ],
   "source": [
    "model20hflip = create_model()\n",
    "\n",
    "train_model(model20hflip, train_generator20hflip, val_generator20hflip, name=\"20percent_Rotation+Horizontal_Flip_Model\", n_epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding random vertical flip and brightness range\n",
    "\n",
    "Even if the previous model isn't overfitting anymore, we'll try a last data augmentation ton see if we can get a better result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Setting the data generator\n",
    "datagen20bothflips = ImageDataGenerator(validation_split=0.2,\n",
    "                                    rotation_range=20,\n",
    "                                    horizontal_flip=True,\n",
    "                                    vertical_flip=True,\n",
    "                                    brightness_range=(0.2, 0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40000 images belonging to 10 classes.\n",
      "Found 8000 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "####### Retrieving data using the ImageDataGenerator\n",
    "train_generator20bothflips ,val_generator20bothflips = retrieve_data(datagen20bothflips,\n",
    "                                               TRAIN_BASE_DIRECTORY,\n",
    "                                               VAL_BASE_DIRECTORY,\n",
    "                                               BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16, 16, 64)        2112      \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                40970     \n",
      "=================================================================\n",
      "Total params: 80,906\n",
      "Trainable params: 80,906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "  2/625 [..............................] - ETA: 5:00 - loss: 17.7585 - accuracy: 0.0703WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0979s vs `on_train_batch_end` time: 0.8673s). Check your callbacks.\n",
      "625/625 [==============================] - 71s 113ms/step - loss: 2.0877 - accuracy: 0.3173 - val_loss: 1.6995 - val_accuracy: 0.3964\n",
      "Epoch 2/20\n",
      "625/625 [==============================] - 72s 115ms/step - loss: 1.6453 - accuracy: 0.4144 - val_loss: 1.5589 - val_accuracy: 0.4391\n",
      "Epoch 3/20\n",
      "625/625 [==============================] - 64s 103ms/step - loss: 1.5385 - accuracy: 0.4591 - val_loss: 1.4836 - val_accuracy: 0.4724\n",
      "Epoch 4/20\n",
      "625/625 [==============================] - 71s 113ms/step - loss: 1.4538 - accuracy: 0.4901 - val_loss: 1.4499 - val_accuracy: 0.4810\n",
      "Epoch 5/20\n",
      "625/625 [==============================] - 74s 119ms/step - loss: 1.4068 - accuracy: 0.5031 - val_loss: 1.3946 - val_accuracy: 0.5061\n",
      "Epoch 6/20\n",
      "625/625 [==============================] - 70s 112ms/step - loss: 1.3613 - accuracy: 0.5209 - val_loss: 1.3466 - val_accuracy: 0.5242\n",
      "Epoch 7/20\n",
      "625/625 [==============================] - 69s 110ms/step - loss: 1.3240 - accuracy: 0.5350 - val_loss: 1.3160 - val_accuracy: 0.5335\n",
      "Epoch 8/20\n",
      "625/625 [==============================] - 66s 105ms/step - loss: 1.2873 - accuracy: 0.5496 - val_loss: 1.2737 - val_accuracy: 0.5462\n",
      "Epoch 9/20\n",
      "625/625 [==============================] - 67s 107ms/step - loss: 1.2648 - accuracy: 0.5554 - val_loss: 1.2827 - val_accuracy: 0.545561 \n",
      "Epoch 10/20\n",
      "625/625 [==============================] - 70s 112ms/step - loss: 1.2451 - accuracy: 0.5634 - val_loss: 1.3305 - val_accuracy: 0.5314\n",
      "Epoch 11/20\n",
      "625/625 [==============================] - 67s 107ms/step - loss: 1.2279 - accuracy: 0.5669 - val_loss: 1.2267 - val_accuracy: 0.5669\n",
      "Epoch 12/20\n",
      "625/625 [==============================] - 68s 108ms/step - loss: 1.2119 - accuracy: 0.5728 - val_loss: 1.2143 - val_accuracy: 0.5741\n",
      "Epoch 13/20\n",
      "625/625 [==============================] - 69s 110ms/step - loss: 1.1952 - accuracy: 0.5793 - val_loss: 1.2641 - val_accuracy: 0.5601\n",
      "Epoch 14/20\n",
      "625/625 [==============================] - 71s 114ms/step - loss: 1.1912 - accuracy: 0.5825 - val_loss: 1.2453 - val_accuracy: 0.5577\n",
      "Epoch 15/20\n",
      "625/625 [==============================] - 72s 115ms/step - loss: 1.1745 - accuracy: 0.5869 - val_loss: 1.1702 - val_accuracy: 0.5851\n",
      "Epoch 16/20\n",
      "625/625 [==============================] - 69s 111ms/step - loss: 1.1665 - accuracy: 0.5911 - val_loss: 1.2215 - val_accuracy: 0.5698\n",
      "Epoch 17/20\n",
      "625/625 [==============================] - 69s 111ms/step - loss: 1.1588 - accuracy: 0.5917 - val_loss: 1.1999 - val_accuracy: 0.5745\n",
      "Epoch 18/20\n",
      "625/625 [==============================] - 72s 116ms/step - loss: 1.1538 - accuracy: 0.5930 - val_loss: 1.1791 - val_accuracy: 0.5798\n",
      "Epoch 19/20\n",
      "625/625 [==============================] - 68s 109ms/step - loss: 1.1388 - accuracy: 0.5980 - val_loss: 1.2136 - val_accuracy: 0.5749\n",
      "Epoch 20/20\n",
      "625/625 [==============================] - 67s 108ms/step - loss: 1.1297 - accuracy: 0.6046 - val_loss: 1.1602 - val_accuracy: 0.5893\n"
     ]
    }
   ],
   "source": [
    "model20bothflips = create_model()\n",
    "\n",
    "train_model(model20bothflips, train_generator20bothflips, val_generator20bothflips, name=\"20percent_Rotation+Horizontal_Vertical_Flip_Brightness_Model\", n_epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data viz\n",
    "\n",
    "Check and uncheck models to make graphs more readable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 8005 (pid 11640), started 0:58:57 ago. (Use '!kill 11640' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-242fee2af70ab36\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-242fee2af70ab36\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 8005;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs --host=localhost --port=8005"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "As we went through the different phases of data augmentation, we noticed an improvement of the loss. At the start, we could clearly see that the model was overfitting.\n",
    "\n",
    "Combining all the previously used data augmentation techniques resulted in a model where validation loss is almost the exact same as the training loss.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "21018cda348434c781f8be1101698e50d4bc452dbd3ed7e1ed7f61bde854e7cd"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
